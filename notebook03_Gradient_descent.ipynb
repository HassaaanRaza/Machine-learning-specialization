{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9abaa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code gives the implementation of gradient descent algothim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224bd180",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([1.0, 2.0])\n",
    "y_train = np.array([300.0, 500.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a796f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 200\n",
    "b = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649c167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Compute the cost function for linear regression.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray(m,)): Input features, m examples\n",
    "        y (ndarray(m,)): Target values\n",
    "        w (float): Weight parameter\n",
    "        b (float): Bias parameter\n",
    "\n",
    "    Returns:\n",
    "        float: The cost (mean squared error / 2) of using w, b as parameters\n",
    "               to fit the data points x and y.\n",
    "    \"\"\"\n",
    "    m = x.shape[0]  # number of training examples\n",
    "    cost_sum = 0.0\n",
    "\n",
    "    # Loop through all training examples\n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b       # prediction\n",
    "        cost = (f_wb - y[i])**2   # squared error\n",
    "        cost_sum += cost\n",
    "\n",
    "    # Average cost\n",
    "    total_cost = (1 / (2 * m)) * cost_sum\n",
    "    return total_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91eaedc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at w = 200, b = 100 : 0.0 \n"
     ]
    }
   ],
   "source": [
    "cost = compute_cost(X_train, y_train, w, b)\n",
    "\n",
    "print(f\"cost at w = {w}, b = {b} : {cost} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cfe4a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent determines the values of w, b that minimize the cost function\n",
    "# 1st we will calculate gradient than gradient descent\n",
    "\n",
    "def compute_gradient(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression.\n",
    "    Args:\n",
    "        x (ndarray (m,)) : Data, m examples.\n",
    "        y (ndarrat (m,)) : target values.\n",
    "        w, b (scalar)    : model parameters.\n",
    "\n",
    "    Returns:\n",
    "        d_w (scalar): The gradient of cost w.r.t the parameter w.\n",
    "        d_b (scalar): The gradient of cost w.r.t the parameter b.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    # gradient is calculating derivative\n",
    "    gradient_w_sum = 0\n",
    "    gradient_b_sum = 0\n",
    "\n",
    "    m = len(x)\n",
    "\n",
    "    for i in range(m):\n",
    "\n",
    "        f_wb = w*x[i] + b\n",
    "\n",
    "        gradient_w_i = (f_wb - y[i])*x[i]\n",
    "        gradient_b_i = (f_wb - y[i])\n",
    "\n",
    "        gradient_w_sum += gradient_w_i\n",
    "        gradient_b_sum += gradient_b_i\n",
    "\n",
    "    d_w = (1/m)*gradient_w_sum\n",
    "    d_b = (1/m)*gradient_b_sum\n",
    "\n",
    "    return d_w, d_b\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9429816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this implement the gradient descent for various values\n",
    "\n",
    "def gradient_descent(w_in, alpa, b_in, X, y, cost, gradient):\n",
    "\n",
    "    J_history = []\n",
    "    p_history = []\n",
    "\n",
    "    b = b_in\n",
    "    w = w_in\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        dj_dw, dj_db = compute_gradient(X,y,w,b)\n",
    "\n",
    "        b = b - alpha * dj_db\n",
    "        w = w - alpha * dj_dw\n",
    "\n",
    "        if i<100000:\n",
    "            J_history.append(cost_function(x, y, w , b))\n",
    "            p_history.append([w, b])\n",
    "\n",
    "\n",
    "        if i % math.ceil(len(X)/10) == 0:\n",
    "            print(f\"Iteration {i:4} : Cost {J_history[-1] : 0.2e}\",\n",
    "                  f\"dj_dw : {dj_dw : 0.3e}, dj_dw : {dj_db : 0.3e}\",\n",
    "                  f\"w : {w : 0.3e}, b : {b : 0.5e}\")\n",
    "\n",
    "    return w, b, J_history, p_history     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb75b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint at iteration 0\n",
      "Checkpoint at iteration 8\n",
      "Checkpoint at iteration 16\n",
      "Checkpoint at iteration 24\n",
      "Checkpoint at iteration 32\n",
      "Checkpoint at iteration 40\n",
      "Checkpoint at iteration 48\n",
      "Checkpoint at iteration 56\n",
      "Checkpoint at iteration 64\n",
      "Checkpoint at iteration 72\n",
      "spaced: 0\n",
      "spaced: 1\n",
      "spaced: 2\n",
      "spaced: 3\n",
      "spaced: 4\n",
      "spaced: 5\n",
      "spaced: 6\n",
      "spaced: 7\n",
      "spaced: 8\n",
      "spaced: 9\n",
      "spaced:10\n",
      "spaced:11\n",
      "spaced:12\n",
      "spaced:13\n",
      "spaced:14\n",
      "spaced:15\n",
      "spaced:16\n",
      "spaced:17\n",
      "spaced:18\n",
      "spaced:19\n",
      "1.23e-06\n"
     ]
    }
   ],
   "source": [
    "# this demonstrate the use of math.ceil\n",
    "\n",
    "num_iters = 77   # total iterations\n",
    "for i in range(num_iters + 1):   # loop from 0 to 50\n",
    "    if i % math.ceil(num_iters/10) == 0:\n",
    "        print(f\"Checkpoint at iteration {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a869aa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaced: 0\n",
      "spaced: 1\n",
      "spaced: 2\n",
      "spaced: 3\n",
      "spaced: 4\n",
      "spaced: 5\n",
      "spaced: 6\n",
      "spaced: 7\n",
      "spaced: 8\n",
      "spaced: 9\n",
      "spaced:10\n",
      "spaced:11\n",
      "spaced:12\n",
      "spaced:13\n",
      "spaced:14\n",
      "spaced:15\n",
      "spaced:16\n",
      "spaced:17\n",
      "spaced:18\n",
      "spaced:19\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(f\"spaced:{i:2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc7b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23e-06\n"
     ]
    }
   ],
   "source": [
    "value = 0.00000123456\n",
    "print(f\"{value:0.2e}\") # effectively convert in power of e, with 2 digits after the decimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05602e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
